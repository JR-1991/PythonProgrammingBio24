{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZyevmLCgYPB"
      },
      "source": [
        "# Exercise 005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idtNqXkegYPD",
        "tags": []
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAIRChemistry/PythonProgrammingBio24/blob/main/exercises/Exercise005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT8TQT1ZgZO6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Please execute this cell to download the necessary data\n",
        "!wget https://github.com/JR-1991/PythonProgrammingBio24/raw/main/data/gc_len_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8eJ-jkaoeEcR"
      },
      "outputs": [],
      "source": [
        "# Please execute this cell to install the necessary packages\n",
        "!pip install seaborn matplotlib pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbNx_QaHeEcR"
      },
      "source": [
        "## Data Clustering #1\n",
        "\n",
        "Read in the data `gc_len_data.csv` using Pandas, perform KMeans clustering, visualize the result with a suitable plot, and compare it to the original data.\n",
        "\n",
        "What do you notice? Was the data clustered correctly?\n",
        "\n",
        "**Tips**\n",
        "\n",
        "> * To visualize the data, you may want to use a dimensionality reduction method, such as the Principal Component Analysis, to confirm the clustering result visually. Check the Sciki-Learn's documentation for guidance on implementing your own method. If you're having trouble, you can use the implementation from the previous exercise, available [here](https://jr-1991.github.io/PythonProgrammingBio24/solutions/Exercise004/).\n",
        "> * This dataset consists of various data types, but the clustering method only works with numeric data. Use the `filter` method to narrow down the dataset to columns that are compatible with the algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "yubzZtmteEcR"
      },
      "outputs": [],
      "source": [
        "# Enter Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uND38-7eEcR"
      },
      "source": [
        "## Data Clustering #2\n",
        "\n",
        "KMeans is a powerful algorithm for detecting clusters, but it requires prior knowledge and assumes linear decision boundaries. Determining the appropriate number of 'classes' in your dataset can be challenging. Review SciKit-Learn's [documentation](https://scikit-learn.org/stable/modules/clustering.html) on clustering algorithms and try out at least one or two of them to repeat the previous task.\n",
        "\n",
        "How do they perform? Which one do you prefer and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "X0cB0raLeEcS"
      },
      "outputs": [],
      "source": [
        "# Enter Code gere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEySviQbeEcS"
      },
      "source": [
        "## Implementing KMeans\n",
        "\n",
        "Your task is to implement the kmeans function using the provided helper functions. The kmeans function should take the input data points, the number of clusters, the maximum number of iterations, and the tolerance for convergence as arguments. It should return the final centroids and the labels assigned to each data point. The implementation is outlined as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRubDmYXeEcS"
      },
      "source": [
        "1. Initialize centroids\n",
        "\n",
        "    * Use the `initialize_centroids` function to randomly select initial centroids from the data points.\n",
        "\n",
        "2. Iterate until convergence or maximum iterations:\n",
        "\n",
        "    * In each iteration\n",
        "        * Assign labels to each data point based on the nearest centroid using the assign_labels function.\n",
        "        * Compute new centroids as the mean of all points assigned to each cluster using the compute_centroids function.\n",
        "        * Check for convergence using the has_converged function.\n",
        "        * If converged, break the loop.\n",
        "\n",
        "3. Return results:\n",
        "    * Return the final centroids and the labels assigned to each data point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ouOcMVYeEcS"
      },
      "source": [
        "### Helper functions\n",
        "\n",
        "Execute the following cell to make use of the helper functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "7pDk9_SxeEcS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def initialize_centroids(X, n_clusters):\n",
        "    \"\"\"\n",
        "    Randomly initialize centroids from the data points.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): The input data points.\n",
        "        n_clusters (int): The number of clusters.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The initialized centroids.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    random_indices = np.random.permutation(X.shape[0])\n",
        "    centroids = X[random_indices[:n_clusters]]\n",
        "    return centroids\n",
        "\n",
        "def assign_labels(X, centroids):\n",
        "    \"\"\"\n",
        "    Assign labels to each data point based on the nearest centroid.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): The input data points.\n",
        "        centroids (numpy.ndarray): The current centroids.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The labels assigned to each data point.\n",
        "    \"\"\"\n",
        "    distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
        "    labels = np.argmin(distances, axis=1)\n",
        "    return labels\n",
        "\n",
        "def compute_centroids(X, labels, n_clusters):\n",
        "    \"\"\"\n",
        "    Compute new centroids as the mean of all points assigned to each cluster.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): The input data points.\n",
        "        labels (numpy.ndarray): The labels assigned to each data point.\n",
        "        n_clusters (int): The number of clusters.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The new centroids.\n",
        "    \"\"\"\n",
        "    centroids = np.zeros((n_clusters, X.shape[1]))\n",
        "    for k in range(n_clusters):\n",
        "        cluster_points = X[labels == k]\n",
        "        if len(cluster_points) > 0:\n",
        "            centroids[k] = np.mean(cluster_points, axis=0)\n",
        "    return centroids\n",
        "\n",
        "def has_converged(old_centroids, new_centroids, tol):\n",
        "    \"\"\"\n",
        "    Check if the centroids have converged.\n",
        "\n",
        "    Args:\n",
        "        old_centroids (numpy.ndarray): The old centroids.\n",
        "        new_centroids (numpy.ndarray): The new centroids.\n",
        "        tol (float): The tolerance for convergence.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the centroids have converged, False otherwise.\n",
        "    \"\"\"\n",
        "    return np.all(np.abs(old_centroids - new_centroids) < tol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "f89C5ssBeEcS"
      },
      "outputs": [],
      "source": [
        "def kmeans(df, n_clusters=3, max_iter=300, tol=1e-4):\n",
        "    \"\"\"\n",
        "    Apply the KMeans clustering algorithm.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): The input data points.\n",
        "        n_clusters (int): The number of clusters.\n",
        "        max_iter (int): The maximum number of iterations.\n",
        "        tol (float): The tolerance for convergence.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The final centroids and the labels assigned to each data point.\n",
        "    \"\"\"\n",
        "\n",
        "    # Leave this to convert the DataFrame to NumPy\n",
        "    X = df.select_dtypes(include='number')\n",
        "\n",
        "    # Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}