{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZyevmLCgYPB"
   },
   "source": [
    "# Exercise 004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idtNqXkegYPD",
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FAIRChemistry/PythonProgrammingBio24/blob/main/exercises/Exercise004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gT8TQT1ZgZO6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please execute this cell to download the necessary data\n",
    "!wget https://github.com/JR-1991/PythonProgrammingBio24/raw/main/data/gc_len_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please execute this cell to install the necessary packages\n",
    "!pip install seaborn matplotlib pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of Distributions #1\n",
    "\n",
    "Read the CSV file `gc_len_data.csv` using the Pandas method `pd.read_csv(path)` and store the result in `DataFrame` in variable `df`. Now use `seaborn` or `matplotlib` to visualize the distribution of all seqeunce lengths found in column `lens`.\n",
    "\n",
    "**Tips**\n",
    "\n",
    "> * Importing a package is done via `import package` where package is substituted with the name of the package you want to import. You can also rename a package by using``import package as renamed` where renamed is the new with which you can use the pckage.\n",
    "> * By convention, `pandas` is always imported as `pd` and `seaborn` as `sns`\n",
    "> Seaborn allows you to directly use a Pandas `DataFrame` object (stored in variable `df`). In the following is a usage example:\n",
    "\n",
    "**Example**\n",
    "\n",
    "Please refer to our [notes](https://jr-1991.github.io/PythonProgrammingBio24/notes/Seminar_004/) for an in-depth example.\n",
    "\n",
    "```python\n",
    "# Seaborn - We pass in the data and specify which column to use\n",
    "sns.countplot(x=\"a_column\", data=df)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coloration by class\n",
    "\n",
    "Repeat the visualization, but now color the distribution in relation to the organism. Which conclusions can you gather from the new plot?\n",
    "\n",
    "**Tips**\n",
    "\n",
    "> * Some methods found in Seaborns have an argument with which you can specifiy to colour by a specific column. These can be categorical or numerical.\n",
    "> * Use the argument `multiple` to specifiy how to handle multiple categories in Seaborn's `histplot` or `kdeplot`. See the [documentation](https://seaborn.pydata.org/api.html) to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code gere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of Distributions #2\n",
    "\n",
    "Repeat the first exercise now for the gc content using the column `gc`. Can you detect a trend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code here (without classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code here (with classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of bivariate data\n",
    "\n",
    "In many of our applications and experiments, we want to understand how two features are related to each other. For example, we might want to examine how two variables are correlated in order to develop a hypothesis. In addition to using a quantitative measure like the \"R-Squared\" value, it can be helpful to create a graph that displays the relationship between the two variables.\n",
    "\n",
    "Calculate the Correlation Matrix of dataset `df` and print the result. Now visualize both columns `gc` and `lens` in a single plot.\n",
    "\n",
    "**Tips**\n",
    "\n",
    "> * The example [gallery](https://seaborn.pydata.org/examples/index.html) of Seaborn can be very inspiring!\n",
    "> * Pandas can calculate a lot of statistic too. See [here](https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html#) and [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional data\n",
    "\n",
    "It's not uncommon for data to have more columns than we can easily comprehend in our three-dimensional world. In these cases, we can use techniques like dimensionality reduction and visualization to help us understand the data better. One of the most popular methods for dimensionality reduction is called [Principle Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA). This statistical technique helps us identify the components that explain most of the variation in the data.\n",
    "\n",
    "To use PCA, we need to utilize a module called `scikit-learn`, which also contains many other machine learning algorithms. Since the `df` dataset comprises not only `gc` and `lens` but also individual codon usage, we can use PCA to demonstrate that our classes are more or less distinctive. To apply PCA to the dataset, please make use of the provided `pca` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute this cell to use the function\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def pca(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes a DataFrame and calculates the first two principle components\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The data used to gather the PCs\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting PCA data \n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = MinMaxScaler()    \n",
    "    data = scaler.fit_transform(data.select_dtypes(include='number'))\n",
    "    \n",
    "    pcs = PCA(n_components=2).fit_transform(data)\n",
    "    \n",
    "    return pd.DataFrame(\n",
    "        {\"PC1\": pcs[:, 0], \"PC2\": pcs[:, 1]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter Code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
